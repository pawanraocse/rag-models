{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"phi3\"\n",
    "#MODEL = \"mixtral:8x7b\"\n",
    "#MODEL = \"llama2\"\n",
    "\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=al5AUq_bxMc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Reema has two daughters sita and gita\\n\\nQuestion: Who is sita\\'s sister?\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Reema has two daughters sita and gita\", question=\"Who is sita's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gita'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\"context\":\"Reema has two daughters sita and gita\", \"question\":\"Who is sita's sister?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription file already exists.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import whisper\n",
    "import tempfile\n",
    "\n",
    "YOUTUBE_VIDEO = 'https://www.youtube.com/watch?v=al5AUq_bxMc'\n",
    "\n",
    "# Function to download audio using yt-dlp\n",
    "def download_audio(url, output_path):\n",
    "    try:\n",
    "        # Run yt-dlp as a subprocess\n",
    "        result = subprocess.run(\n",
    "            ['yt-dlp', '-x', '--audio-format', 'mp3', '-o', output_path, url],\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        print(\"yt-dlp output:\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"yt-dlp error output:\", e.stderr)\n",
    "        raise\n",
    "\n",
    "# Let's do this only if we haven't created the transcription file yet.\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        audio_path = os.path.join(tmpdir, \"audio.mp3\")\n",
    "        try:\n",
    "            download_audio(YOUTUBE_VIDEO, audio_path)\n",
    "            \n",
    "            # Let's load the base model. This is not the most accurate\n",
    "            # model but it's fast.\n",
    "            whisper_model = whisper.load_model(\"base\")\n",
    "            transcription = whisper_model.transcribe(audio_path, fp16=False)[\"text\"].strip()\n",
    "\n",
    "            with open(\"transcription.txt\", \"w\") as file:\n",
    "                file.write(transcription)\n",
    "\n",
    "            print(\"Transcription saved to transcription.txt\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Failed to download and process the audio.\")\n",
    "else:\n",
    "    print(\"Transcription file already exists.\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi guys, today we are going to look at a leadcode '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"transcription.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "transcription[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'transcription.txt'}, page_content='Hi guys, today we are going to look at a leadcode problem contains duplicate. In this problem we have an integer array numbs and we need to find whether that integer array contains any duplicate value or not. If it contains any duplicate value we need to return true, else we need to return false. To solve this problem we are going to use a set of integer. Set basically have a property to contain only non distinct value and the search time of a set is big of one. So it will give the constant search time. So let us iterate over this integer array and here we are going to check if set contains this value n then we will return false. Otherwise we will simply add the element into the set. It does not contain any return value so from here we will return false. So here we need to return true if it contains a duplicate then we are returning true if not then we are returning false. Let us try to run. Submit.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(documents, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video discusses a method to check if an attempt to submit something includes duplicates and the associated lead code issue that arises when there are big sets involved, potentially causing problems with submission timing. The focus seems to be on troubleshooting or identifying issues within these procedures of submitting leads containing codes in large datasets.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "result = chain.invoke({\"question\": \"What is this video about?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This YouTube video seems to be explaining how set times are calculated for leads in music or performance settings based on a code they call \"leadcode.\" They mention that if certain conditions met by the leadtime value, it returns true (presumably indicating acceptable timing), otherwise false. However, I need more information about 'leadcode' and its calculations to give an accurate description of this video content.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({'question': \"What is this video about?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
